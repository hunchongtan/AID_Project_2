{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Design Structure Matrix\n",
    "\n",
    "Dear user, given an official manual of the product, \\\n",
    "we will compare the official components against the components mentioned in other sources \\\n",
    "in the form of design structure matrixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIREMENTS\n",
    "\n",
    "For this notebook, you need to have:\n",
    "- 1 x Pickle file of Scrapped data from an **Official Manual** in _current_ folder (from Chap2.ipynb)\n",
    "- 4 x Pickle files of Scrapped data from other Online sources in _current_ folder (from Chap2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dear user, enter your Product here!\n",
    "'''\n",
    "\n",
    "product = \"PICO 4 All-in-One VR Headset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dear user, enter the directory to the Official Manual here!\n",
    "'''\n",
    "manual = \"support/_current_/user_manual/user_manual.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dear user, enter the directories to the 4 other sources here!\n",
    "'''\n",
    "youtube_data = \"support/_current_/youtube/comments.txt\"\n",
    "reddit_data = \"support/_current_/reddit/comments.txt\"\n",
    "pc_gamer_data = \"support/_current_/pc_gamer/pc_gamer.txt\"\n",
    "product_desc_data = \"support/_current_/product_desc/product_desc.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN AS INTENDED (DO NOT CHANGE ANYTHING.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.9 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: chromadb==0.4.24 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.24)\n",
      "Requirement already satisfied: langchain-openai==0.0.8 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (0.1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain==0.1.9) (8.2.3)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.1.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.102.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.23.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.17.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.23.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.13.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (6.0.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (1.62.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (0.10.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb==0.4.24) (3.9.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-openai==0.0.8) (1.13.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-openai==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb==0.4.24) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb==0.4.24) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb==0.4.24) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb==0.4.24) (6.8.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb==0.4.24) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fastapi>=0.95.2->chromadb==0.4.24) (0.27.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.9) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.15.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.24) (2.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-core<0.2,>=0.1.26->langchain==0.1.9) (3.7.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (2.0.7)\n",
      "Requirement already satisfied: protobuf in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (3.19.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.24) (1.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.24.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.24) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24) (1.59.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.23.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.24) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.44b0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (0.44b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\tanhu\\appdata\\roaming\\python\\python39\\site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.24) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.4.24) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.4.24) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.9) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.9) (2.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langchain==0.1.9) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.9) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2023.8.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer>=0.9.0->chromadb==0.4.24) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.24) (11.0.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources->chromadb==0.4.24) (3.17.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain==0.1.9) (1.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (4.9)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.17.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.9) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.24) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.24) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.24) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.24) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain==0.1.9 chromadb==0.4.24 langchain-openai==0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set up OpenAI API key \"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")       # LangChain requires API key in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create DSM folder \"\"\"\n",
    "import pandas as pd\n",
    "search_terms = pd.read_pickle(\"support/_current_/searchTerms.pkl\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "try:\n",
    "    os.makedirs(\"support/%s/%s\" % (search_terms, \"DSM\"))\n",
    "except FileExistsError:\n",
    "    shutil.rmtree('support/%s/DSM' % search_terms)\n",
    "    os.makedirs(\"support/%s/%s\" % (search_terms, \"DSM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_vector_store(file):\n",
    "    \"\"\" Remove 'persist' directory, if any \"\"\"\n",
    "    try:\n",
    "        shutil.rmtree('support/%s/persist' % search_terms)       # remove old version\n",
    "        print(\"Deleting previous store\")\n",
    "    except:\n",
    "        print(\"No store found\")\n",
    "    \n",
    "    \"\"\" Load Private Documents of User Manual \"\"\"\n",
    "    from langchain.document_loaders import TextLoader\n",
    "\n",
    "    loader = TextLoader(file, encoding='utf-8')\n",
    "    document = loader.load()\n",
    "\n",
    "    \"\"\" Split Documents into smaller parts \"\"\"\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    splits = text_splitter.split_documents(document)\n",
    "\n",
    "    \"\"\" Use OpenAI Embeddings \"\"\"\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    \"\"\" Create back 'persist' directory \"\"\"\n",
    "    persist_directory = 'support/%s/persist' % search_terms     # create new version\n",
    "\n",
    "    \"\"\" Apply embeddings on private documents and save in 'persist' directory \"\"\"\n",
    "    from langchain.vectorstores import Chroma\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=splits,                           # target the splits created from the documents loaded\n",
    "        embedding=embedding,                        # use the OpenAI embedding specified\n",
    "        persist_directory=persist_directory         # store in the persist directory for future use\n",
    "    )\n",
    "\n",
    "    vectordb.persist()                              # store vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Official Components from User Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query ChatGPT for the Official Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_query(file, question, save):\n",
    "    \"\"\" Retrieve vectordb created \"\"\"\n",
    "    import pandas as pd\n",
    "    search_terms = pd.read_pickle(\"support/_current_/searchTerms.pkl\")\n",
    "\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    from langchain.vectorstores import Chroma\n",
    "    persist_directory = 'support/%s/persist' % search_terms\n",
    "\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embedding\n",
    "        )\n",
    "\n",
    "    print(\"Processing folder:\", search_terms)\n",
    "    print(\"Size of Vector Database\", vectordb._collection.count())    # same as before\n",
    "    \n",
    "    \"\"\" Apply language model and vectordb for Chatbot \"\"\"\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "                    \n",
    "    from langchain.chains import RetrievalQA\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 15, \"fetch_k\": 10}),\n",
    "        # retriever=vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4}),\n",
    "        # retriever=vectordb.as_retriever(),\n",
    "        return_source_documents=True\n",
    "        )\n",
    "    \n",
    "    \"\"\" Ready to use GPT \"\"\"\n",
    "    template = \" Express the answer only as a Python list containing a short non-descriptive name of the physical component. If you don't know the answer to the question, just come up with the components.\"\n",
    "\n",
    "    prompt = question + template\n",
    "    result = qa_chain({\"query\": prompt})\n",
    "\n",
    "    components = result[\"result\"]\n",
    "    print(\"Components:\", components)\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(components, open(\"support/%s/DSM/%s.pkl\" % (search_terms, save), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No store found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify ten key physical components for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43minitiate_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m private_query(manual, question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mofficial_components\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m, in \u001b[0;36minitiate_vector_store\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Apply embeddings on private documents and save in 'persist' directory \"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m---> 33\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;66;43;03m# target the splits created from the documents loaded\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# use the OpenAI embedding specified\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# store in the persist directory for future use\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m vectordb\u001b[38;5;241m.\u001b[39mpersist()\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    777\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    779\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    780\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    781\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    782\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    783\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    784\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    785\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    786\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    787\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    731\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    732\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    733\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    734\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    735\u001b[0m     ):\n\u001b[1;32m--> 736\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    742\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:508\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain_openai\\embeddings\\base.py:324\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    322\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 324\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    328\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    919\u001b[0m         request,\n\u001b[0;32m    920\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    922\u001b[0m     )\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\httpx\\_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    914\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\httpx\\_client.py:909\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 909\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\httpx\\_models.py:805\u001b[0m, in \u001b[0;36mResponse.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\httpx\\_models.py:824\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m--> 824\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n\u001b[0;32m    826\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\httpx\\_decoders.py:76\u001b[0m, in \u001b[0;36mGZipDecoder.decode\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m zlib\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DecodingError(\u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question = f\"Identify ten key physical components for {product}.\"\n",
    "initiate_vector_store(manual)\n",
    "private_query(manual, question, \"official_components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No store found\n",
      "Processing folder: PICO 4 All-in-One VR Headset\n",
      "Size of Vector Database 2025\n",
      "Components: [\"VR Headset\", \"Controllers\", \"Batteries\", \"Glasses Spacer\", \"Nose Pad\", \"Controller Lanyards\", \"USB-C Power Adapter\", \"USB-C to C 2.0 Data Cable\", \"Face Cushion\", \"Top Strap\"]\n"
     ]
    }
   ],
   "source": [
    "question = f\"Identify ten most mentioned physical components for {product}.\"\n",
    "initiate_vector_store(youtube_data)\n",
    "private_query(youtube_data, question, \"youtube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No store found\n",
      "Processing folder: PICO 4 All-in-One VR Headset\n",
      "Size of Vector Database 3741\n",
      "Components: [\"headstrap\", \"face shield\", \"face cushion\", \"top strap\", \"metal buckle\", \"foam\", \"pro controllers\", \"display\", \"audio\", \"hardware\"]\n"
     ]
    }
   ],
   "source": [
    "question = f\"Identify ten most mentioned physical components for {product}.\"\n",
    "initiate_vector_store(reddit_data)\n",
    "private_query(reddit_data, question, \"reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No store found\n",
      "Processing folder: PICO 4 All-in-One VR Headset\n",
      "Size of Vector Database 3757\n",
      "Components: [\"headset\", \"glasses spacer\", \"wheel adjustment\", \"nose pad\", \"headband\", \"face shield\", \"foam\", \"controllers\", \"passthrough control\", \"audio\"]\n"
     ]
    }
   ],
   "source": [
    "question = f\"Identify ten most mentioned physical components for {product}.\"\n",
    "initiate_vector_store(pc_gamer_data)\n",
    "private_query(pc_gamer_data, question, \"pc_gamer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No store found\n",
      "Processing folder: PICO 4 All-in-One VR Headset\n",
      "Size of Vector Database 3766\n",
      "Components: [\"Fast-LCD screens\", \"headset\", \"controllers\", \"settings menu\", \"optical sensors\", \"nose pad\", \"headband\", \"wheel adjustment\", \"glasses spacer\", \"infrared optical positioning system\"]\n"
     ]
    }
   ],
   "source": [
    "question = f\"Identify ten most mentioned physical components for {product}.\"\n",
    "initiate_vector_store(product_desc_data)\n",
    "private_query(product_desc_data, question, \"product_desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_DSM(file):\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from openai import OpenAI\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        # Load official components data\n",
    "        official_components_data = pd.read_pickle(f\"support/{search_terms}/DSM/official_components.pkl\")\n",
    "        file_data = pd.read_pickle(f\"support/{search_terms}/DSM/{file}.pkl\")\n",
    "\n",
    "        client = OpenAI()\n",
    "\n",
    "        question = f\"Given 2 lists of physical components, {official_components_data} and {file_data}, design a Design Structure Matrix with 1s and 0s to compare the physical components.\"\n",
    "        template = \"  Express the answer only as a Python dictionary (with double quotes, strictly no single quotes). The first key should be empty with the value as the components from the first list. the key as a compared component from the second list (do not add numbering) and the value as the 1s and 0s. Do not add additional comments. Only output the dictionary.\"\n",
    "        prompt = question + template\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.5,  # adjust persona and temperature\n",
    "        )\n",
    "\n",
    "        result = chat_completion.choices[0].message.content\n",
    "        print(result)  # Print the result\n",
    "\n",
    "        data = json.loads(result)\n",
    "\n",
    "        components = data[\"\"]\n",
    "        del data[\"\"]  # Remove the first key since it represents an empty string\n",
    "\n",
    "        # Construct DSM matrix\n",
    "        num_components = len(components)\n",
    "        dsm_matrix = np.zeros((num_components, num_components), dtype=int)\n",
    "\n",
    "        for i, component in enumerate(components):\n",
    "            for j, compared_component in enumerate(components):\n",
    "                dsm_matrix[i, j] = data.get(component, [0]*num_components)[j]\n",
    "\n",
    "        # Display DSM\n",
    "        plt.imshow(dsm_matrix, cmap='viridis', interpolation='nearest')\n",
    "        plt.xticks(np.arange(num_components), components, rotation=45, ha='right')\n",
    "        plt.yticks(np.arange(num_components), components)\n",
    "        plt.title(\"Design Structure Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Invalid Response. Please regenerate.\")\n",
    "        print(e)  # Print the exception for debugging purposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_DSM(file):\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from openai import OpenAI\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        # Load official components data\n",
    "        official_components_data = pd.read_pickle(f\"support/{search_terms}/DSM/official_components.pkl\")\n",
    "        file_data = pd.read_pickle(f\"support/{search_terms}/DSM/{file}.pkl\")\n",
    "\n",
    "        client = OpenAI()\n",
    "\n",
    "        question = f\"Given 2 lists of physical components, {official_components_data} and {file_data}, design a Design Structure Matrix with 1s and 0s to compare the physical components.\"\n",
    "        template = \"  Express the answer only as a Python dictionary (with double quotes, strictly no single quotes). The first key should be empty with the value as the components from the first list. the key as a compared component from the second list (do not add numbering) and the value as the 1s and 0s. Do not add additional comments. Only output the dictionary.\"\n",
    "        prompt = question + template\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.5,  # adjust persona and temperature\n",
    "        )\n",
    "\n",
    "        result = chat_completion.choices[0].message.content\n",
    "\n",
    "        dsm_data = json.loads(result)\n",
    "\n",
    "        components = dsm_data[\"\"]\n",
    "        del dsm_data[\"\"]\n",
    "\n",
    "        # Construct DSM DataFrame\n",
    "        dsm_df = pd.DataFrame(dsm_data, index=components)\n",
    "\n",
    "        print(\"Design Structure Matrix:\")\n",
    "        print(dsm_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Invalid Response. Please regenerate.\")\n",
    "        print(e)  # Print the exception for debugging purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Structure Matrix:\n",
      "                            VR Headset  Controllers  Batteries  \\\n",
      "VR Headset                           1            0          0   \n",
      "Controllers                          0            1          0   \n",
      "1.5V AA Alkaline Batteries           0            0          1   \n",
      "Glasses Spacer                       0            0          0   \n",
      "Nose Pad                             0            0          0   \n",
      "Controller Lanyards                  0            0          0   \n",
      "USB-C Power Adapter                  0            0          0   \n",
      "USB-C to C 2.0 Data Cable            0            0          0   \n",
      "Face Cushion                         0            0          0   \n",
      "Top Strap                            0            0          0   \n",
      "\n",
      "                            Glasses Spacer  Nose Pad  Controller Lanyards  \\\n",
      "VR Headset                               0         0                    0   \n",
      "Controllers                              0         0                    0   \n",
      "1.5V AA Alkaline Batteries               0         0                    0   \n",
      "Glasses Spacer                           1         0                    0   \n",
      "Nose Pad                                 0         1                    0   \n",
      "Controller Lanyards                      0         0                    1   \n",
      "USB-C Power Adapter                      0         0                    0   \n",
      "USB-C to C 2.0 Data Cable                0         0                    0   \n",
      "Face Cushion                             0         0                    0   \n",
      "Top Strap                                0         0                    0   \n",
      "\n",
      "                            USB-C Power Adapter  USB-C to C 2.0 Data Cable  \\\n",
      "VR Headset                                    0                          0   \n",
      "Controllers                                   0                          0   \n",
      "1.5V AA Alkaline Batteries                    0                          0   \n",
      "Glasses Spacer                                0                          0   \n",
      "Nose Pad                                      0                          0   \n",
      "Controller Lanyards                           0                          0   \n",
      "USB-C Power Adapter                           1                          0   \n",
      "USB-C to C 2.0 Data Cable                     0                          1   \n",
      "Face Cushion                                  0                          0   \n",
      "Top Strap                                     0                          0   \n",
      "\n",
      "                            Face Cushion  Top Strap  \n",
      "VR Headset                             0          0  \n",
      "Controllers                            0          0  \n",
      "1.5V AA Alkaline Batteries             0          0  \n",
      "Glasses Spacer                         0          0  \n",
      "Nose Pad                               0          0  \n",
      "Controller Lanyards                    0          0  \n",
      "USB-C Power Adapter                    0          0  \n",
      "USB-C to C 2.0 Data Cable              0          0  \n",
      "Face Cushion                           1          0  \n",
      "Top Strap                              0          1  \n"
     ]
    }
   ],
   "source": [
    "auto_DSM('youtube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Structure Matrix:\n",
      "                            headstrap  face shield  face cushion  top strap  \\\n",
      "VR Headset                          0            0             0          0   \n",
      "Controllers                         0            0             0          0   \n",
      "1.5V AA Alkaline Batteries          0            0             0          0   \n",
      "Glasses Spacer                      0            0             0          0   \n",
      "Nose Pad                            0            0             0          0   \n",
      "Controller Lanyards                 0            0             0          0   \n",
      "USB-C Power Adapter                 0            0             0          0   \n",
      "USB-C to C 2.0 Data Cable           0            0             0          0   \n",
      "Face Cushion                        0            0             1          0   \n",
      "Top Strap                           1            0             0          1   \n",
      "\n",
      "                            metal buckle  foam  pro controllers  display  \\\n",
      "VR Headset                             0     0                0        0   \n",
      "Controllers                            0     0                1        0   \n",
      "1.5V AA Alkaline Batteries             0     0                0        0   \n",
      "Glasses Spacer                         0     0                0        0   \n",
      "Nose Pad                               0     0                0        0   \n",
      "Controller Lanyards                    0     0                0        0   \n",
      "USB-C Power Adapter                    0     0                0        0   \n",
      "USB-C to C 2.0 Data Cable              0     0                0        0   \n",
      "Face Cushion                           0     0                0        0   \n",
      "Top Strap                              0     0                0        0   \n",
      "\n",
      "                            audio  hardware  \n",
      "VR Headset                      0         0  \n",
      "Controllers                     0         0  \n",
      "1.5V AA Alkaline Batteries      0         0  \n",
      "Glasses Spacer                  0         0  \n",
      "Nose Pad                        0         0  \n",
      "Controller Lanyards             0         0  \n",
      "USB-C Power Adapter             0         0  \n",
      "USB-C to C 2.0 Data Cable       0         0  \n",
      "Face Cushion                    0         0  \n",
      "Top Strap                       0         0  \n"
     ]
    }
   ],
   "source": [
    "auto_DSM('reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Structure Matrix:\n",
      "                            headset  glasses spacer  wheel adjustment  \\\n",
      "VR Headset                        1               0                 0   \n",
      "Controllers                       0               0                 0   \n",
      "1.5V AA Alkaline Batteries        0               0                 0   \n",
      "Glasses Spacer                    0               1                 0   \n",
      "Nose Pad                          0               0                 0   \n",
      "Controller Lanyards               0               0                 0   \n",
      "USB-C Power Adapter               0               0                 0   \n",
      "USB-C to C 2.0 Data Cable         0               0                 0   \n",
      "Face Cushion                      0               0                 0   \n",
      "Top Strap                         0               0                 0   \n",
      "\n",
      "                            nose pad  headband  face shield  foam  \\\n",
      "VR Headset                         0         0            0     0   \n",
      "Controllers                        0         0            0     0   \n",
      "1.5V AA Alkaline Batteries         0         0            0     0   \n",
      "Glasses Spacer                     0         0            0     0   \n",
      "Nose Pad                           1         0            0     0   \n",
      "Controller Lanyards                0         0            0     0   \n",
      "USB-C Power Adapter                0         0            0     0   \n",
      "USB-C to C 2.0 Data Cable          0         0            0     0   \n",
      "Face Cushion                       0         0            1     0   \n",
      "Top Strap                          0         1            0     0   \n",
      "\n",
      "                            controllers  passthrough control  audio  \n",
      "VR Headset                            0                    0      0  \n",
      "Controllers                           1                    0      0  \n",
      "1.5V AA Alkaline Batteries            0                    0      0  \n",
      "Glasses Spacer                        0                    0      0  \n",
      "Nose Pad                              0                    0      0  \n",
      "Controller Lanyards                   0                    0      0  \n",
      "USB-C Power Adapter                   0                    0      0  \n",
      "USB-C to C 2.0 Data Cable             0                    0      0  \n",
      "Face Cushion                          0                    0      0  \n",
      "Top Strap                             0                    0      0  \n"
     ]
    }
   ],
   "source": [
    "auto_DSM('pc_gamer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Structure Matrix:\n",
      "                            Fast-LCD screens  headset  controllers  \\\n",
      "VR Headset                                 0        1            0   \n",
      "Controllers                                0        0            1   \n",
      "1.5V AA Alkaline Batteries                 0        0            0   \n",
      "Glasses Spacer                             0        0            0   \n",
      "Nose Pad                                   0        0            0   \n",
      "Controller Lanyards                        0        0            0   \n",
      "USB-C Power Adapter                        0        0            0   \n",
      "USB-C to C 2.0 Data Cable                  0        0            0   \n",
      "Face Cushion                               0        0            0   \n",
      "Top Strap                                  0        0            0   \n",
      "\n",
      "                            settings menu  optical sensors  nose pad  \\\n",
      "VR Headset                              0                0         0   \n",
      "Controllers                             0                0         0   \n",
      "1.5V AA Alkaline Batteries              0                0         0   \n",
      "Glasses Spacer                          0                0         0   \n",
      "Nose Pad                                0                0         1   \n",
      "Controller Lanyards                     0                0         0   \n",
      "USB-C Power Adapter                     0                0         0   \n",
      "USB-C to C 2.0 Data Cable               0                0         0   \n",
      "Face Cushion                            0                0         0   \n",
      "Top Strap                               0                0         0   \n",
      "\n",
      "                            headband  wheel adjustment  glasses spacer  \\\n",
      "VR Headset                         0                 0               0   \n",
      "Controllers                        0                 0               0   \n",
      "1.5V AA Alkaline Batteries         0                 0               0   \n",
      "Glasses Spacer                     0                 0               1   \n",
      "Nose Pad                           0                 0               0   \n",
      "Controller Lanyards                0                 0               0   \n",
      "USB-C Power Adapter                0                 0               0   \n",
      "USB-C to C 2.0 Data Cable          0                 0               0   \n",
      "Face Cushion                       0                 0               0   \n",
      "Top Strap                          0                 0               0   \n",
      "\n",
      "                            infrared optical positioning system  \n",
      "VR Headset                                                    0  \n",
      "Controllers                                                   0  \n",
      "1.5V AA Alkaline Batteries                                    0  \n",
      "Glasses Spacer                                                0  \n",
      "Nose Pad                                                      0  \n",
      "Controller Lanyards                                           0  \n",
      "USB-C Power Adapter                                           0  \n",
      "USB-C to C 2.0 Data Cable                                     0  \n",
      "Face Cushion                                                  0  \n",
      "Top Strap                                                     0  \n"
     ]
    }
   ],
   "source": [
    "auto_DSM('product_desc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
