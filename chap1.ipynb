{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Initial Query with ChatGPT\n",
    "\n",
    "Dear user, you are part of a consulting firm tasked to: \\\n",
    "[1] identify opportunities for design improvements for a specific product \\\n",
    "[2] conduct benchmarking with competitors whenever appropriate.\n",
    "\n",
    "In this initial stage, we will initialize the **product** \\\n",
    "and gather initial insights and directions via querying a LLM (**ChatGPT**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dear user, enter your Product here!\n",
    "'''\n",
    "\n",
    "product = \"PICO 4 All-in-One VR Headset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'support\\\\PICO 4 All-in-One VR Headset\\\\persist\\\\a8cc0ac9-003f-4c36-a617-648599b18771\\\\data_level0.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m):                     \u001b[38;5;66;03m# Delete 'support' folder if it exists\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msupport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:759\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:624\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    622\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mislink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 624\u001b[0m     \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:624\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    622\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mislink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 624\u001b[0m     \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:624\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    622\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mislink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 624\u001b[0m     \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:629\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    627\u001b[0m             os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m             \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mc:\\Users\\tanhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py:627\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'support\\\\PICO 4 All-in-One VR Headset\\\\persist\\\\a8cc0ac9-003f-4c36-a617-648599b18771\\\\data_level0.bin'"
     ]
    }
   ],
   "source": [
    "\"\"\" Use this for a fresh set up (Comment if not needed) \"\"\"\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('support'):                     # Delete 'support' folder if it exists\n",
    "    shutil.rmtree('support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN AS INTENDED (DO NOT CHANGE ANYTHING.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\tanhu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set up OpenAI API key \"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory PICO 4 All-in-One VR Headset exists\n",
      "Directory ChatGPT created\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create directory \"\"\"\n",
    "import os\n",
    "\n",
    "try:                                              # Create directory named after search terms\n",
    "    os.makedirs(\"support/%s\" % search_terms)\n",
    "    print(\"Directory\", search_terms, \"created\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory\", search_terms, \"exists\")\n",
    "\n",
    "try:                                              # Create directory to store ChatGPT\n",
    "    os.makedirs(\"support/%s/%s\" % (search_terms, \"ChatGPT\"))\n",
    "    print(\"Directory ChatGPT created\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory ChatGPT exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DESIGN OPPORTUNITIES QUERY with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Opportunities Query with ChatGPT:\n",
      "       Component                           Description\n",
      "0    Head straps     Need for more comfortable padding\n",
      "1    Controllers          Improve the ergonomic design\n",
      "2   Battery life             Increase for longer usage\n",
      "3  Audio quality      Enhance for immersive experience\n",
      "4         Weight    Reduce for comfort during long use\n",
      "5            FOV  Increase for better visual immersion\n",
      "6     Resolution           Enhance for clearer visuals\n",
      "7      Interface        Simplify for easier navigation\n",
      "8   Connectivity         Improve for stable connection\n",
      "9         Lenses       Improve quality to reduce glare\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Design Opportunities Query with ChatGPT \"\"\"\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "question =  f\"Identify and rank ten opportunities for design improvements with the {product}.\"\n",
    "template = \" Express the answer only as a Python dictionary (with double quotes, strictly no single quotes) with the key as a physical component (do not add numbering) and the value as a concised explanation with a maximum of 45 characters. If you don't know the answer to the question, strictly state 'I don't know'.\"\n",
    "prompt = question + template\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "    temperature=0.5,                                        # adjust persona and temperature\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "\n",
    "pickle.dump(result, open(\"support/%s/%s/chatgpt_design_opportunities.pkl\" % (product, \"ChatGPT\"), \"wb\"))\n",
    "\n",
    "data_string = pd.read_pickle(\"support/%s/%s/chatgpt_design_opportunities.pkl\" % (product, \"ChatGPT\"))\n",
    "data = json.loads(data_string)\n",
    "\n",
    "try:\n",
    "    components = list(data.keys())\n",
    "    descriptions = list(data.values())\n",
    "\n",
    "    df = pd.DataFrame({'Component': components, 'Description': descriptions})\n",
    "\n",
    "    print(\"Design Opportunities Query with ChatGPT:\")\n",
    "    print(df)\n",
    "except:\n",
    "        print(\"Invalid Response. Please regenerate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BENCHMARKING QUERY with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Query with ChatGPT:\n",
      "Oculus Quest 2\n",
      "            Component                                       Benchmarking\n",
      "0             Headset  Pico lighter & smaller, Quest 2 better resolution\n",
      "1         Controllers       Pico's are simpler, Quest 2's more ergonomic\n",
      "2       Power Adapter                   Both have similar power adapters\n",
      "3      Glasses Spacer                    Quest 2 includes, Pico does not\n",
      "4      Charging Cable                     Both use USB-C charging cables\n",
      "5           Headstrap       Quest 2's is more comfortable and adjustable\n",
      "6   Touch Controllers           Pico's lack touch capacity, Quest 2's do\n",
      "7        AA Batteries         Quest 2 controllers require, Pico's do not\n",
      "8         USB-C Cable              Both headsets come with a USB-C cable\n",
      "9  Instruction Manual                Both have clear and concise manuals\n",
      "\n",
      "\n",
      "HTC Vive Pro\n",
      "        Component                              Benchmarking\n",
      "0         Headset  Pico is lighter, Vive Pro has higher res\n",
      "1   Base Stations               Vive Pro has, Pico does not\n",
      "2     Controllers              Both have motion controllers\n",
      "3        Link Box               Vive Pro has, Pico does not\n",
      "4  Power Adapters                  Both have power adapters\n",
      "5    Mounting Kit               Vive Pro has, Pico does not\n",
      "6       USB Cable                      Both have USB cables\n",
      "7      HDMI Cable               Vive Pro has, Pico does not\n",
      "8         Earbuds                         Both have earbuds\n",
      "9  Cleaning Cloth               Both include cleaning cloth\n",
      "\n",
      "\n",
      "Sony PlayStation VR\n",
      "                     Component                           Benchmarking\n",
      "0                   VR Headset  PICO is lighter, both have HD screens\n",
      "1               Processor Unit       PICO has built-in, PSVR external\n",
      "2  VR Headset Connection Cable           PICO is wireless, PSVR wired\n",
      "3                   HDMI Cable       PICO doesn't need, PSVR requires\n",
      "4                    USB Cable              Used for charging in both\n",
      "5            Stereo Headphones             Both have integrated audio\n",
      "6                AC Power Cord           Both have, used for charging\n",
      "7                   AC Adapter                Both come with adapters\n",
      "8     PlayStation VR Demo Disc            PICO doesn't have, PSVR has\n",
      "9           PlayStation Camera       PICO has built-in, PSVR external\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" BENCHMARKING QUERY with ChatGPT \"\"\"\n",
    "\n",
    "\"\"\" Get 3 competitors \"\"\"\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "search_terms = product\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "question =  f\"Identify three competitors of the {product} and the top ten physical components of each competitor.\"\n",
    "template = \" Express the answer only as a Python dictionary (with double quotes, strictly no single quotes) with the key as the product name (do not add numbering) and the value as a Python list of the ten components. If you don't know the answer to the question, strictly state ' '.\"\n",
    "prompt = question + template\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "    temperature=0.5,                                        # adjust persona and temperature\n",
    ")\n",
    "\n",
    "result = chat_completion.choices[0].message.content\n",
    "\n",
    "pickle.dump(result, open(\"support/%s/%s/chatgpt_competitors.pkl\" % (product, \"ChatGPT\"), \"wb\"))\n",
    "\n",
    "\"\"\" Benchmarking \"\"\"\n",
    "print(\"Benchmarking Query with ChatGPT:\")\n",
    "data_string = pd.read_pickle(\"support/%s/%s/chatgpt_competitors.pkl\" % (product, \"ChatGPT\"))\n",
    "data = json.loads(data_string)\n",
    "try:\n",
    "    competitors = list(data.keys())\n",
    "    components = list(data.values())\n",
    "    client = OpenAI()\n",
    "\n",
    "    for i in range(len(competitors)):\n",
    "        question = f\"Using the {product}, conduct benchmarking with {competitors[i]} with regards to these ten physical components: {data[competitors[i]]}.\"\n",
    "        template = \" Express the answer only as a Python dictionary (with double quotes, strictly no single quotes) with the key as a physical component (do not add numbering) and the value as a concised explanation with a maximum of 45 characters. If you don't know the answer to the question, strictly state 'I don't know.'.\"\n",
    "        prompt = question + template\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.5,  # adjust persona and temperature\n",
    "        )\n",
    "\n",
    "        result = chat_completion.choices[0].message.content\n",
    "\n",
    "        pickle.dump(result, open(\"support/%s/%s/chatgpt_%s_benchmarking.pkl\" % (product, \"ChatGPT\", competitors[i]), \"wb\"))\n",
    "\n",
    "        data_string = pd.read_pickle(\"support/%s/%s/chatgpt_%s_benchmarking.pkl\" % (product, \"ChatGPT\", competitors[i]))\n",
    "        benchmarking_data = json.loads(data_string)\n",
    "        try:\n",
    "            components = list(benchmarking_data.keys())\n",
    "            descriptions = list(benchmarking_data.values())\n",
    "\n",
    "            df = pd.DataFrame({'Component': components, 'Benchmarking': descriptions})\n",
    "\n",
    "            print(competitors[i])\n",
    "            print(df)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"Invalid Response. Please regenerate.\")\n",
    "except:\n",
    "        print(\"Invalid Response. Please regenerate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
